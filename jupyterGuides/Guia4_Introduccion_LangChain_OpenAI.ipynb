{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83152e03",
      "metadata": {
        "id": "83152e03"
      },
      "source": [
        "# Guía 3 — Introducción a LangChain con OpenAI API\n",
        "Curso: **IA en el Aula — Nivel Avanzado**  \n",
        "Profesor: **Luis Daniel Benavides Navarro**  \n",
        "Fecha: **Octubre 2025**\n",
        "\n",
        "En esta guía aprenderás los conceptos básicos de **LangChain**, una librería diseñada para construir aplicaciones impulsadas por modelos de lenguaje, integrando la API de OpenAI con flujos más complejos. Exploraremos cómo crear un primer **prompt chain**, administrar memoria y usar herramientas para componer respuestas inteligentes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Cargar la clave y crear el cliente en google Colab\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "print(\"Cliente inicializado. Modelo listo para consultas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqkYtfwibrWy",
        "outputId": "fae59b51-c8d7-4674-adab-09165b692b6d"
      },
      "id": "SqkYtfwibrWy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cliente inicializado. Modelo listo para consultas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4929bd",
      "metadata": {
        "id": "1b4929bd"
      },
      "source": [
        "## 1️⃣ Instalación y configuración inicial\n",
        "LangChain se instala como cualquier otra librería de Python. También usaremos `python-dotenv` para gestionar la clave de OpenAI. Ejecute la siguiente celda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aca0e6f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aca0e6f9",
        "outputId": "f9c64555-3674-4fa2-976c-23e9c5ab815f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.35\n"
          ]
        }
      ],
      "source": [
        "%pip install openai langchain python-dotenv langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aee39b5",
      "metadata": {
        "id": "5aee39b5"
      },
      "source": [
        "## 2️⃣ Cargar variables de entorno y cliente OpenAI\n",
        "Crea un archivo `.env` con tu clave de API y cárgala para poder usarla dentro de LangChain. Esto evita exponer tu clave en el código fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4b3fcb82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3fcb82",
        "outputId": "ff5598e7-fe16-4d2d-d3f6-0097bcc52129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cliente LangChain con OpenAI inicializado correctamente.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "load_dotenv()  # Cargar archivo .env\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
        "\n",
        "# Crear cliente LangChain con OpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e2926d",
      "metadata": {
        "id": "65e2926d"
      },
      "source": [
        "## 3️⃣ Primer ejemplo: Prompt simple con LangChain\n",
        "LangChain utiliza **chains** (cadenas de pasos) para procesar información. Comencemos con una cadena simple que envía un mensaje al modelo y obtiene la respuesta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0769dbb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0769dbb6",
        "outputId": "bebff2a2-c0d3-4ace-dc35-306c76492042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender de datos y mejorar su rendimiento en tareas específicas sin ser programadas explícitamente. Utiliza algoritmos que identifican patrones y hacen predicciones basadas en la información proporcionada.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize the LLM (uses your OpenAI API key from environment)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "\n",
        "# Create a simple prompt\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Explica en dos frases el concepto de {tema}.\"\n",
        ")\n",
        "\n",
        "# Combine the components using LCEL (LangChain Expression Language)\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run it\n",
        "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5349f8b",
      "metadata": {
        "id": "a5349f8b"
      },
      "source": [
        "### Explicación\n",
        "- **ChatPromptTemplate:** define la estructura del mensaje que se envía al modelo.\n",
        "- **ChatOpenAI:** la conexión real al modelo.\n",
        "- **chain** crea la cadena de componentes usando LCEL (LangChain Expression Language).\n",
        "- **StrOutputParser** convierte la salida estructurada del modelo en texto plano.\n",
        "- **chain.invoke:** ejecuta la cadena pasando los valores del prompt.\n",
        "\n",
        "Este patrón permite reutilizar prompts para distintos temas o contextos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6939352f",
      "metadata": {
        "id": "6939352f"
      },
      "source": [
        "## 4️⃣ Ejemplo 2: Encadenar múltiples pasos\n",
        "LangChain permite combinar varios pasos en una misma ejecución. En este ejemplo, crearemos dos prompts: uno para definir un tema y otro para generar una aplicación educativa basada en el resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b6cd03c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6cd03c2",
        "outputId": "c7747d9d-6dfe-40e4-9f09-37ca5561a1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Aplicación Educativa: \"Aventuras en la Historia\"**\n",
            "\n",
            "**Descripción General:**\n",
            "\"Aventuras en la Historia\" es una aplicación educativa de realidad aumentada diseñada para estudiantes de educación primaria y secundaria. Su objetivo es hacer que el aprendizaje de la historia sea más interactivo y atractivo al permitir a los estudiantes explorar eventos históricos, personajes clave y lugares significativos a través de la superposición de contenido digital en su entorno real.\n",
            "\n",
            "**Características Clave:**\n",
            "\n",
            "1. **Exploración de Sitios Históricos:**\n",
            "   - Los estudiantes pueden visitar sitios históricos locales o nacionales y, al apuntar su dispositivo hacia ellos, ver reconstrucciones en 3D de cómo eran en el pasado. Por ejemplo, al apuntar a una antigua fortaleza, podrían ver cómo se veía en su apogeo con soldados, banderas y actividades cotidianas.\n",
            "\n",
            "2. **Interacción con Personajes Históricos:**\n",
            "   - La aplicación permite a los usuarios \"conocer\" a personajes históricos mediante avatares en 3D que aparecen en su entorno. Estos avatares pueden contar historias, responder preguntas y participar en diálogos interactivos, lo que fomenta un aprendizaje más profundo y personal.\n",
            "\n",
            "3. **Línea del Tiempo Interactiva:**\n",
            "   - Los estudiantes pueden crear una línea del tiempo de eventos históricos clave utilizando la RA. Al escanear un espacio en su aula o en casa, pueden ver los eventos superpuestos en el tiempo y espacio, facilitando la comprensión de la cronología y las conexiones entre diferentes eventos.\n",
            "\n",
            "4. **Actividades y Desafíos:**\n",
            "   - La aplicación incluye desafíos y juegos educativos que invitan a los estudiantes a resolver acertijos o completar misiones relacionadas con eventos históricos. Esto puede incluir la búsqueda de artefactos virtuales escondidos en su entorno o la resolución de problemas que requieran el uso de información histórica.\n",
            "\n",
            "5. **Recursos Educativos:**\n",
            "   - Se proporcionan recursos adicionales, como videos, artículos y actividades complementarias, que los maestros pueden utilizar para enriquecer las lecciones en el aula. Los estudiantes pueden acceder a estos recursos a través de la aplicación, lo que les permite profundizar en los temas que les interesan.\n",
            "\n",
            "6. **Colaboración y Compartición:**\n",
            "   - Los estudiantes pueden trabajar en grupos para explorar diferentes aspectos de un evento histórico y luego presentar sus hallazgos a la clase. La aplicación permite la compartición de experiencias y descubrimientos a través de redes sociales educativas, fomentando la colaboración.\n",
            "\n",
            "**Beneficios:**\n",
            "- Mejora el compromiso y la motivación de los estudiantes al aprender sobre historia de una manera dinámica y visual.\n",
            "- Facilita la comprensión de conceptos complejos al proporcionar contexto visual y narrativo.\n",
            "- Promueve el aprendizaje activo y la investigación personal, lo que puede resultar en una mayor retención del conocimiento.\n",
            "\n",
            "**Implementación:**\n",
            "La aplicación podría ser desarrollada en colaboración con educadores y expertos en historia para asegurar que el contenido sea preciso y relevante. Además, se podría ofrecer formación a los maestros sobre cómo integrar esta herramienta en sus lecciones. \n",
            "\n",
            "\"Aventuras en la Historia\" no solo enriquecería el aprendizaje de la historia, sino que también fomentaría habilidades como el pensamiento crítico, la colaboración y la creatividad en los estudiantes.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "to_str = StrOutputParser()\n",
        "\n",
        "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
        "primer_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Explica brevemente el concepto de {tema}.\"\n",
        ")\n",
        "primer_paso = primer_prompt | llm | to_str\n",
        "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
        "\n",
        "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
        "segundo_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
        ")\n",
        "segundo_paso = segundo_prompt | llm | to_str\n",
        "\n",
        "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
        "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
        "\n",
        "# 5) Ejecutar la cadena completa\n",
        "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf949db6",
      "metadata": {
        "id": "cf949db6"
      },
      "source": [
        "### Explicación\n",
        "- **cadena_secuencial:** permite conectar varias cadenas; la salida de una se convierte en la entrada de la siguiente.\n",
        "- En este caso, el modelo primero explica el tema y luego sugiere una aplicación educativa.\n",
        "\n",
        "Este tipo de flujo es ideal para generar contenido didáctico o ideas para proyectos en clase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d0483d0",
      "metadata": {
        "id": "0d0483d0"
      },
      "source": [
        "## 5️⃣ Ejemplo 3: Añadir memoria a la conversación\n",
        "LangChain incluye módulos de **memoria** para mantener contexto entre múltiples interacciones. Esto permite simular conversaciones educativas más naturales, donde el modelo recuerda temas previos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d363f018",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d363f018",
        "outputId": "8e5aae26-b2b5-4e70-cd1a-1576d507c42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Hola! Encantado de ayudarte. ¿En qué puedo asistirte hoy en relación a la informática?\n",
            "Claro, aquí tienes algunos pasos para introducir la inteligencia artificial (IA) a tus estudiantes:\n",
            "\n",
            "1. **Conceptos Básicos**: Comienza explicando qué es la IA, su historia y sus aplicaciones en la vida cotidiana. Puedes usar ejemplos como asistentes virtuales (Siri, Alexa), recomendaciones de películas (Netflix) y chatbots.\n",
            "\n",
            "2. **Tipos de IA**: Introduce los diferentes tipos de IA, como IA débil (especializada en tareas específicas) y IA fuerte (que puede entender y aprender de manera similar a los humanos).\n",
            "\n",
            "3. **Fundamentos Técnicos**: Explica conceptos básicos como algoritmos, aprendizaje automático (machine learning) y redes neuronales. Puedes usar diagramas y visualizaciones para facilitar la comprensión.\n",
            "\n",
            "4. **Herramientas y Lenguajes**: Presenta herramientas y lenguajes de programación populares en IA, como Python, TensorFlow y scikit-learn. Proporciona ejemplos de código simple.\n",
            "\n",
            "5. **Proyectos Prácticos**: Fomenta el aprendizaje práctico a través de proyectos. Por ejemplo, crear un modelo simple de predicción o un chatbot básico. Esto les permitirá aplicar lo aprendido.\n",
            "\n",
            "6. **Ética en IA**: Discute la importancia de la ética en el desarrollo y uso de IA. Plantea preguntas sobre sesgos, privacidad y el impacto social de la IA.\n",
            "\n",
            "7. **Recursos Adicionales**: Proporciona recursos como cursos en línea, libros y tutoriales para que los estudiantes puedan profundizar en el tema.\n",
            "\n",
            "8. **Invitados Especiales**: Considera invitar a profesionales del campo de la IA para que compartan sus experiencias y conocimientos.\n",
            "\n",
            "Recuerda adaptar el contenido al nivel de tus estudiantes y fomentar un ambiente de curiosidad y preguntas. ¡Buena suerte!\n",
            "Aquí tienes algunos ejemplos prácticos que puedes utilizar en clase para enseñar sobre inteligencia artificial:\n",
            "\n",
            "1. **Chatbots Simples**: Utiliza plataformas como Chatbot.com o herramientas como Dialogflow para que los estudiantes creen su propio chatbot. Pueden programar respuestas a preguntas comunes.\n",
            "\n",
            "2. **Clasificación de Imágenes**: Usa herramientas como Teachable Machine de Google, donde los estudiantes pueden entrenar un modelo para clasificar imágenes (por ejemplo, reconocer diferentes tipos de frutas).\n",
            "\n",
            "3. **Análisis de Sentimientos**: Introduce a los estudiantes al procesamiento de lenguaje natural (NLP) utilizando bibliotecas como NLTK o TextBlob en Python. Pueden analizar comentarios de redes sociales o reseñas de productos para determinar el sentimiento (positivo, negativo, neutral).\n",
            "\n",
            "4. **Predicción de Datos**: Proporciona un conjunto de datos (por ejemplo, precios de casas) y enseña a los estudiantes a usar herramientas como Scikit-learn para crear un modelo de regresión que prediga precios basados en características.\n",
            "\n",
            "5. **Reconocimiento de Voz**: Usa APIs como Google Cloud Speech-to-Text para que los estudiantes experimenten con el reconocimiento de voz, creando aplicaciones que conviertan voz a texto.\n",
            "\n",
            "6. **Juegos con IA**: Introduce juegos simples como \"Tic-Tac-Toe\" o \"Adivina el número\" donde los estudiantes programen una IA que juegue contra ellos.\n",
            "\n",
            "7. **Generación de Arte**: Utiliza herramientas como DeepArt o DALL-E para mostrar cómo la IA puede generar imágenes o arte a partir de texto o estilos artísticos.\n",
            "\n",
            "8. **Proyectos de IA en el Mundo Real**: Anima a los estudiantes a investigar y presentar proyectos de IA en uso, como sistemas de recomendación en plataformas de streaming o diagnósticos médicos asistidos por IA.\n",
            "\n",
            "9. **Simulaciones de Redes Neuronales**: Usa plataformas como Google Colab para que los estudiantes puedan experimentar con redes neuronales simples y ver cómo se entrenan en tiempo real.\n",
            "\n",
            "10. **Debates sobre Ética**: Organiza un debate donde los estudiantes discutan temas éticos relacionados con la IA, como la privacidad de los datos, el sesgo algorítmico y el futuro del trabajo.\n",
            "\n",
            "Estos ejemplos no solo ayudarán a los estudiantes a entender los conceptos de IA, sino que también fomentarán la creatividad y el pensamiento crítico. ¡Diviértete enseñando!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instalar si hace falta:\n",
        "# %pip install -U langchain langchain-openai\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "to_str = StrOutputParser()\n",
        "\n",
        "# Prompt con hueco para el historial\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Cadena base\n",
        "chain = prompt | llm | to_str\n",
        "\n",
        "# Memoria simple como lista de mensajes\n",
        "history: list = []\n",
        "\n",
        "def chat(user_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
        "    con el par (usuario, asistente).\n",
        "    \"\"\"\n",
        "    global history\n",
        "    # Ejecutar la cadena inyectando el historial actual\n",
        "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
        "    # Actualizar memoria (guardar los dos mensajes)\n",
        "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
        "    return answer\n",
        "\n",
        "# --- Ejemplo de uso (tres turnos) ---\n",
        "print(chat(\"Hola, soy un profesor de informática.\"))\n",
        "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
        "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a79423b",
      "metadata": {
        "id": "6a79423b"
      },
      "source": [
        "### Explicación\n",
        "- **ConversationBufferMemory:** almacena los mensajes anteriores en la conversación.\n",
        "- **ConversationChain:** combina el modelo con la memoria.\n",
        "- Esta funcionalidad es útil para tutores inteligentes o chatbots educativos que requieren continuidad en el diálogo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ba0ab9",
      "metadata": {
        "id": "f0ba0ab9"
      },
      "source": [
        "## 6️⃣ Buenas prácticas con LangChain + OpenAI\n",
        "- Usa prompts **claros y estructurados**: el modelo responde mejor cuando la tarea está bien definida.\n",
        "- Controla `temperature` según la tarea: bajo (0.1–0.3) para precisión, alto (0.7–0.9) para creatividad.\n",
        "- Guarda logs o historiales si tu aplicación incluye interacción prolongada.\n",
        "- Limita la longitud de las respuestas con `max_tokens` para evitar costos o respuestas excesivas.\n",
        "- Documenta tus cadenas (`LLMChain`) para reusarlas en distintos contextos educativos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a40d49",
      "metadata": {
        "id": "68a40d49"
      },
      "source": [
        "## ✅ Conclusión\n",
        "Has aprendido los fundamentos de LangChain: prompts, chains, memoria y flujo secuencial. Estos conceptos son la base para desarrollar asistentes educativos, tutores personalizados o sistemas de generación de contenido en el aula. En la próxima guía implementaremos un **asistente educativo con RAG (Retrieval-Augmented Generation)** usando tus propios materiales docentes."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}