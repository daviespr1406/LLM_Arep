{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e32b2a27",
      "metadata": {
        "id": "e32b2a27"
      },
      "source": [
        "# Guía de Instalación y Práctica — Sesión 1 (Notebook)\n",
        "Curso: **IA en el Aula — Nivel Avanzado**  \n",
        "Profesor: **Luis Daniel Benavides Navarro**  \n",
        "Fecha: **22 de octubre de 2025**\n",
        "\n",
        "Este cuaderno guía a los participantes para configurar el entorno, conectarse a una API de modelos de lenguaje y realizar las primeras consultas con **parámetros clave** como `temperature`, `max_tokens`, `top_p`, etc. Se incluyen explicaciones paso a paso y ejercicios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4be0ddd",
      "metadata": {
        "id": "c4be0ddd"
      },
      "source": [
        "## 1) Requisitos previos\n",
        "- Python 3.10 o superior\n",
        "- Cuenta y **clave API** en un proveedor de modelos de lenguaje (ej. OpenAI)\n",
        "- Editor/entorno: VSCode, Jupyter o Colab\n",
        "- Conexión a Internet\n",
        "\n",
        "Si estás en **Colab**, puedes ejecutar el siguiente comando para instalar dependencias. En local, usa tu terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc702d52",
      "metadata": {
        "id": "cc702d52"
      },
      "outputs": [],
      "source": [
        "# (Opcional en local/Colab) Instalar dependencias\n",
        "%pip install --quiet openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b5e55a",
      "metadata": {
        "id": "25b5e55a"
      },
      "source": [
        "## 2) Preparar variables de entorno\n",
        "Crea un archivo `.env` en la carpeta del proyecto con:\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=tu_clave_aqui\n",
        "```\n",
        "Nunca publiques tu clave. Evita subir `.env` a repositorios públicos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80b7f4a",
      "metadata": {
        "id": "a80b7f4a"
      },
      "outputs": [],
      "source": [
        "# 3) Cargar la clave y crear el cliente\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()  # Lee el archivo .env\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "print(\"Cliente inicializado. Modelo listo para consultas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00221859",
      "metadata": {
        "id": "00221859"
      },
      "source": [
        "Si está en Google Colab, debe incluir la llave en los secretos (en el menú de la izquierda), activar la variable y luego inicializar así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ccd38611",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccd38611",
        "outputId": "10378097-1957-4c36-ef67-b1df49f04b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cliente inicializado. Modelo listo para consultas.\n"
          ]
        }
      ],
      "source": [
        "# 3) Cargar la clave y crear el cliente en google Colab\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "print(\"Cliente inicializado. Modelo listo para consultas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174eb5a6",
      "metadata": {
        "id": "174eb5a6"
      },
      "source": [
        "## 4) Parámetros importantes de la API (explicación breve)\n",
        "- **`model`**: identifica el modelo a consultar (p.ej., `gpt-4o-mini`).\n",
        "- **`messages`**: lista de turnos conversacionales. Usa roles `system` (instrucciones generales), `user` (tu prompt), `assistant` (respuestas previas si las hay).\n",
        "- **`temperature`**: *aleatoriedad* de la salida. Valores bajos (0.0–0.3) hacen respuestas más deterministas; valores altos (0.7–1.0) hacen respuestas más creativas.\n",
        "- **`top_p`**: alternativa a `temperature` basada en muestreo por probabilidad acumulada; usa uno u otro (no ambos a la vez a valores lejanos) para afinar el estilo.\n",
        "- **`max_tokens`**: tope de tokens generados en la respuesta. Si es muy bajo, el texto puede cortarse.\n",
        "- **`stop`**: secuencias de corte; si aparecen, la generación se detiene.\n",
        "- **`frequency_penalty` / `presence_penalty`**: penalizaciones para reducir repeticiones y fomentar aparición de nuevos términos.\n",
        "\n",
        "**Buenas prácticas:**\n",
        "- Controlar `temperature` (0.2–0.7) según la tarea (evaluación → bajo; lluvia de ideas → medio/alto).\n",
        "- Estructurar prompts y, cuando sea útil, **pedir JSON** para facilitar la automatización.\n",
        "- Evitar incluir datos personales o sensibles en prompts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "873e7d0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "873e7d0d",
        "outputId": "f4503153-c333-44e5-9b67-d762ee31d44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La inteligencia artificial en la educación se refiere al uso de tecnologías que simulan la inteligencia humana para personalizar el aprendizaje, automatizar tareas administrativas y ofrecer retroalimentación adaptativa a los estudiantes. Estas herramientas pueden analizar el rendimiento de los alumnos, identificar áreas de mejora y facilitar experiencias educativas más efectivas y accesibles.\n"
          ]
        }
      ],
      "source": [
        "# 5) Primera consulta: respuesta libre\n",
        "prompt = \"Explica en dos frases qué es la inteligencia artificial en la educación.\"\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.7  # más creativo que 0.2, menos que 1.0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e281741",
      "metadata": {
        "id": "1e281741"
      },
      "source": [
        "### Comentarios sobre `temperature`\n",
        "- A `0.0–0.2`: respuestas casi siempre iguales (útil en **rubricas** o **explicaciones estándar**).\n",
        "- A `0.5–0.8`: más variación léxica/estilística (útil en **generación de materiales** o **brainstorming**).\n",
        "- A `>0.9`: creatividad alta pero riesgo de salidas menos precisas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0f22c8e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f22c8e4",
        "outputId": "ec705f48-c028-457f-a9c5-950232cdb739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"operation\": \"explanation\",\n",
            "  \"input\": \"¿Qué es aprendizaje supervisado?\",\n",
            "  \"output\": \"El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir o clasificar nuevas entradas basándose en patrones identificados en los datos de entrenamiento.\"\n",
            "}\n",
            "\n",
            "Valid JSON → {'operation': 'explanation', 'input': '¿Qué es aprendizaje supervisado?', 'output': 'El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida correspondiente conocida, lo que permite al modelo aprender a predecir o clasificar nuevas entradas basándose en patrones identificados en los datos de entrenamiento.'}\n"
          ]
        }
      ],
      "source": [
        "# 6) Respuesta estructurada en JSON para automatización\n",
        "import json\n",
        "\n",
        "query = \"¿Qué es aprendizaje supervisado?\"\n",
        "schema_instruction = (\n",
        "    \"Responde en formato JSON con las claves: operation, input, output. \"\n",
        "    \"operation debe ser 'explanation'; input debe repetir la pregunta; output la explicación clara y breve.\"\n",
        ")\n",
        "response_json = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": schema_instruction},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ],\n",
        "    temperature=0.3,       # más determinista para formatos estructurados\n",
        "    max_tokens=300         # suficiente para una explicación breve\n",
        ")\n",
        "text = response_json.choices[0].message.content\n",
        "print(text)\n",
        "\n",
        "# (Opcional) intentar cargar como JSON si el modelo devolvió un objeto válido\n",
        "try:\n",
        "    data = json.loads(text)\n",
        "    print(\"\\nValid JSON →\", data)\n",
        "except json.JSONDecodeError:\n",
        "    print(\"\\nLa salida no es JSON válido literal. Puedes parsearla manualmente o usar validadores/funciones JSON del proveedor.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057a1d82",
      "metadata": {
        "id": "057a1d82"
      },
      "source": [
        "## 7) Ejercicios propuestos\n",
        "1. Cambia `temperature` a 0.1, 0.5 y 0.9 y compara el estilo de las respuestas.\n",
        "2. Pide que el modelo responda **siempre en JSON** usando un `system` que lo exija. Verifica si cumple.\n",
        "3. Crea un prompt de tu área (p.ej., *programación*, *arquitectura*, *matemáticas*) que devuelva un JSON con `operation`, `input`, `steps` (lista) y `output`.\n",
        "4. Limita la longitud con `max_tokens` y observa si corta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0eece738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eece738",
        "outputId": "21332555-378d-4076-bc08-9dfe5d19940a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"promt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
            "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura en forma de árbol para tomar decisiones basadas en características de los datos. Cada nodo interno representa una prueba sobre una característica, cada rama representa el resultado de la prueba y cada hoja representa una clase o decisión final, permitiendo clasificar o predecir resultados a partir de las características de entrada.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Plantilla reutilizable para el curso\n",
        "def ask_model(prompt: str,\n",
        "              model: str = \"gpt-4o-mini\",\n",
        "              temperature: float = 0.3,\n",
        "              max_tokens: int = 400,\n",
        "              system: str | None = None):\n",
        "    messages = []\n",
        "    if system:\n",
        "        messages.append({\"role\": \"system\", \"content\": system})\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(ask_model(\n",
        "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
        "    temperature=0.4,\n",
        "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e9fef7c",
      "metadata": {
        "id": "2e9fef7c"
      },
      "source": [
        "## 9) Solución de problemas comunes\n",
        "- **`openai.AuthenticationError` / `401`**: clave inválida o no cargada; revisa tu `.env` y reinicia el kernel.\n",
        "- **`Rate limit`**: excediste el número de solicitudes por minuto; espera unos segundos y reintenta.\n",
        "- **`model_not_found`**: el modelo no existe o no tienes acceso; cambia a uno disponible en tu cuenta.\n",
        "- **Salidas no JSON**: fija `temperature=0.0–0.3`, agrega instrucciones `system` estrictas y/o usa funciones nativas de validación JSON si el proveedor las ofrece.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0eab4f2",
      "metadata": {
        "id": "b0eab4f2"
      },
      "source": [
        "## 10) Próximos pasos\n",
        "En la siguiente sesión se verán **consultas avanzadas**, manejo de contexto y el punto de partida para construir un **asistente con RAG** (recuperación de conocimiento) usando materiales del curso.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}